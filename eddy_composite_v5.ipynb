{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a feature-centric eddy composite, v5\n",
    "##### New updates from v4: add more interative capabilities so eddy composites (both surface and vertical) can be made for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eddy_tracks\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as colors\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import scipy.interpolate\n",
    "import metpy.calc as mpcalc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(eddy,xlen,ylen,eddy_tracks):\n",
    "    \n",
    "    distances= np.empty([ylen, xlen])\n",
    "    \n",
    "    #Haversine formula, assumes Earth is a sphere\n",
    "    R = 6373.0 #radius of earth (km)\n",
    "\n",
    "    lat1 = eddy_tracks.y.iloc[eddy]\n",
    "    lon1 = eddy_tracks.x.iloc[eddy]\n",
    "\n",
    "    lat2 = ds.TLAT\n",
    "    lon2 = ds.TLONG\n",
    "\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = (np.sin(dlat / 2) * np.sin(dlat / 2) +\n",
    "         np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) *\n",
    "         np.sin(dlon / 2) * np.sin(dlon / 2))\n",
    "\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    distances = R * c\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_coords(databox):\n",
    "\n",
    "        #first do lons\n",
    "        start = -1*int(len(databox.lon)/2)\n",
    "        if len(databox.lon)%2 == 0.:\n",
    "            end=int(len(databox.lon)/2)\n",
    "        else:\n",
    "            end=int(len(databox.lon)/2 + 1)\n",
    "\n",
    "        databox['lon']=np.arange(start,end,1)\n",
    "\n",
    "        #now do lats\n",
    "        start = -1*int(len(databox.lat)/2)\n",
    "\n",
    "        if len(databox.lat)%2 == 0.:\n",
    "            end=int(len(databox.lat)/2)\n",
    "        else:\n",
    "            end=int(len(databox.lat)/2 + 1)\n",
    "\n",
    "        databox['lat']=np.arange(start,end,1) # databox = databox.assign_coords({'lat':np.arange(start,end,1)})\n",
    "\n",
    "        return databox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_a_2D_eddy(eddy_tracks, ds, var, n_reps, threshold_r):\n",
    "\n",
    "    xlen=len(ds.nlon)\n",
    "    ylen=len(ds.nlat)\n",
    "    elen=len(eddy_tracks)\n",
    "    \n",
    "    #initialize sum\n",
    "    sum_databoxes = 0\n",
    "    count_eddies = 0\n",
    "\n",
    "    for eddy in np.arange(0,elen,1):\n",
    "        #print(\"starting eddy \", eddy)\n",
    "\n",
    "        distance = calc_distance(eddy,xlen,ylen,eddy_tracks)\n",
    "\n",
    "        #normalize distance to eddy radius\n",
    "        distance_normrad = distance / eddy_tracks.radius_km.iloc[eddy]\n",
    "\n",
    "        #extract just these values\n",
    "        sorted_distances = np.sort(distance_normrad, axis=None)\n",
    "        sorted_distances = sorted_distances[sorted_distances < threshold_r]\n",
    "        limit_index=len(sorted_distances)\n",
    "\n",
    "        #get the x,y indices of the qualifying gridcells\n",
    "        indices = np.unravel_index(np.argsort(distance_normrad.data, axis=None), distance_normrad.shape)\n",
    "\n",
    "        #make a subset based on the limit index for qualifying distances\n",
    "        indices_subset = (indices[0][:limit_index],indices[1][:limit_index])\n",
    "\n",
    "        #get the four indices for getting out hi res data in the box\n",
    "        x_min, x_max=np.percentile(indices_subset[0], [0,100])\n",
    "        y_min, y_max=np.percentile(indices_subset[1], [0,100])\n",
    "        x_min = int(x_min)\n",
    "        x_max = int(x_max)\n",
    "        y_min = int(y_min)\n",
    "        y_max = int(y_max)\n",
    "\n",
    "        #extract data for the variable with these indices\n",
    "        databox = var[x_min:x_max,y_min:y_max] # databox = var.isel(lon=slice(x_min,x_max+1), lat=slice(y_min,y_max+1))\n",
    "\n",
    "        if np.isnan(databox).any() != True:\n",
    "\n",
    "            count_eddies = count_eddies + 1\n",
    "\n",
    "            #make databox an xr DataArray\n",
    "            databox = xr.DataArray(databox,dims=('lat','lon'))\n",
    "\n",
    "            databox_smooth = mpcalc.smooth_n_point(databox, 9, n_reps)\n",
    "            databox_smooth = xr.DataArray(databox_smooth,dims=('lat','lon'))\n",
    "            databox_smooth.attrs = databox.attrs\n",
    "\n",
    "            #make it anomalies\n",
    "            databox = databox - databox_smooth\n",
    "\n",
    "            #put data in the coordinates so that the eddies can be overlaid with their centers aligned\n",
    "            databox = put_coords(databox)\n",
    "\n",
    "            #now make a running sum\n",
    "            sum_databoxes = sum_databoxes + databox     \n",
    "\n",
    "        else:\n",
    "            print('skipping eddy number', eddy)\n",
    "\n",
    "    #finally, out of the loop, divide by the eddy number so that we have mean\n",
    "    composite = sum_databoxes / count_eddies\n",
    "    \n",
    "    return composite, count_eddies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_a_3D_eddy(eddy_tracks, ds, var, n_reps, threshold_r):\n",
    "    print('got a 3-d var')\n",
    "    xlen=len(ds.nlon)\n",
    "    ylen=len(ds.nlat)\n",
    "    elen=len(eddy_tracks)\n",
    "\n",
    "    #initialize sum\n",
    "    sum_databoxes = 0\n",
    "    count_eddies = 0\n",
    "\n",
    "    ###########first see if there are eddies with nans\n",
    "\n",
    "    eddy_list=[]\n",
    "    eddies_dict = dict()\n",
    "\n",
    "\n",
    "    if var.dims[0]=='z_t':\n",
    "        z_dim = 'z_t'\n",
    "    else:\n",
    "        z_dim = 'z_t_150m'\n",
    "\n",
    "    for eddy in np.arange(0,elen,1):\n",
    "        #print(eddy)\n",
    "        distance = calc_distance(eddy,xlen,ylen,eddy_tracks)\n",
    "\n",
    "        #normalize distance to eddy radius\n",
    "        distance_normrad = distance / eddy_tracks.radius_km.iloc[eddy]\n",
    "\n",
    "        #extract just these values\n",
    "        sorted_distances = np.sort(distance_normrad, axis=None)\n",
    "        sorted_distances = sorted_distances[sorted_distances < threshold_r]\n",
    "        limit_index=len(sorted_distances)\n",
    "\n",
    "        #get the x,y indices of the qualifying gridcells\n",
    "        indices = np.unravel_index(np.argsort(distance_normrad.data, axis=None), distance_normrad.shape)\n",
    "\n",
    "        #make a subset based on the limit index for qualifying distances\n",
    "        indices_subset = (indices[0][:limit_index],indices[1][:limit_index])\n",
    "\n",
    "        #get the four indices for getting out hi res data in the box\n",
    "        x_min, x_max=np.percentile(indices_subset[0], [0,100])\n",
    "        y_min, y_max=np.percentile(indices_subset[1], [0,100])\n",
    "        x_min = int(x_min)\n",
    "        x_max = int(x_max)\n",
    "        y_min = int(y_min)\n",
    "        y_max = int(y_max)\n",
    "\n",
    "        databox = var[0:15, x_min:x_max, y_min:y_max]\n",
    "\n",
    "        #make databox an xr DataArray\n",
    "        databox = xr.DataArray(databox,dims=(z_dim,'lat','lon'))\n",
    "\n",
    "        if np.isnan(var[0:15,x_min:x_max,y_min:y_max]).any() != True:\n",
    "            eddy_list.append(eddy)\n",
    "            \n",
    "            #saving each individual eddy composite ds in a dictionary\n",
    "            eddy_str = str(eddy)\n",
    "            eddies_dict[eddy_str] = databox\n",
    "            \n",
    "            #finding minimum eddy size so that a sums array can be set up \n",
    "            if count_eddies==0:\n",
    "                width=len(databox.lon)\n",
    "                height=len(databox.lat)\n",
    "            else:\n",
    "                width=(min(width, len(databox.lon)))\n",
    "                height=(min(height, len(databox.lat)))\n",
    "                \n",
    "            count_eddies = count_eddies + 1\n",
    "            \n",
    "    #prepare array for summing\n",
    "    sums3d = xr.DataArray(np.zeros([15,height,width]),dims=(z_dim,'lat','lon'))\n",
    "\n",
    "    for z in np.arange(0,15,1):\n",
    "\n",
    "        #print('doing depth',z)\n",
    "        if z_dim=='z_t':\n",
    "            var2d = var.isel(z_t=z).squeeze()\n",
    "        else:\n",
    "            var2d = var.isel(z_t_150m=z).squeeze()\n",
    "\n",
    "        for eddy in eddy_list:\n",
    "\n",
    "            eddy_str = str(eddy)\n",
    "\n",
    "            databox = eddies_dict[eddy_str][z,:,:].squeeze()\n",
    "\n",
    "            databox_smooth = mpcalc.smooth_n_point(databox, 9, n_reps)\n",
    "            databox_smooth = xr.DataArray(databox_smooth,dims=('lat','lon'))\n",
    "            databox_smooth.attrs = databox.attrs\n",
    "\n",
    "            #make it anomalies\n",
    "            databox = databox - databox_smooth\n",
    "\n",
    "            #put data in the coordinates so that the eddies can be overlaid with their centers aligned\n",
    "            databox = put_coords(databox)\n",
    "\n",
    "            #now make a running sum\n",
    "            sum_databoxes = sum_databoxes + databox \n",
    "\n",
    "        sums3d[z,:,:]=sum_databoxes\n",
    "        count_eddies=len(eddy_list)\n",
    "    \n",
    "    composite = sums3d / count_eddies\n",
    "    composite['lat']=sum_databoxes['lat']\n",
    "    composite['lon']=sum_databoxes['lon']\n",
    "    \n",
    "    return composite, count_eddies, sums3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>amp</th>\n",
       "      <th>area</th>\n",
       "      <th>u</th>\n",
       "      <th>age</th>\n",
       "      <th>radius_km</th>\n",
       "      <th>id</th>\n",
       "      <th>cyc</th>\n",
       "      <th>year</th>\n",
       "      <th>mon</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>242.258195</td>\n",
       "      <td>40.498931</td>\n",
       "      <td>2.994491</td>\n",
       "      <td>10809.049919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.656862</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>242.600100</td>\n",
       "      <td>-69.344310</td>\n",
       "      <td>0.125429</td>\n",
       "      <td>1307.723710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.402485</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>242.700100</td>\n",
       "      <td>-64.131685</td>\n",
       "      <td>3.458723</td>\n",
       "      <td>6708.039396</td>\n",
       "      <td>5.631560</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.208606</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>245.400100</td>\n",
       "      <td>-61.955224</td>\n",
       "      <td>13.669557</td>\n",
       "      <td>10985.213312</td>\n",
       "      <td>26.323848</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.132918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>245.600100</td>\n",
       "      <td>-67.146695</td>\n",
       "      <td>0.551876</td>\n",
       "      <td>1666.310001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.030479</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599345</td>\n",
       "      <td>258.500100</td>\n",
       "      <td>-63.513617</td>\n",
       "      <td>6.218261</td>\n",
       "      <td>9476.326775</td>\n",
       "      <td>11.992946</td>\n",
       "      <td>125.0</td>\n",
       "      <td>54.921840</td>\n",
       "      <td>230803</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599346</td>\n",
       "      <td>258.600100</td>\n",
       "      <td>-55.425356</td>\n",
       "      <td>2.878914</td>\n",
       "      <td>6293.522627</td>\n",
       "      <td>8.810720</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.758133</td>\n",
       "      <td>236814</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599347</td>\n",
       "      <td>258.600100</td>\n",
       "      <td>-49.654134</td>\n",
       "      <td>0.655865</td>\n",
       "      <td>8606.090785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>52.339314</td>\n",
       "      <td>235516</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599348</td>\n",
       "      <td>258.800100</td>\n",
       "      <td>-21.714382</td>\n",
       "      <td>0.378134</td>\n",
       "      <td>8417.142072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>51.761564</td>\n",
       "      <td>237872</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599349</td>\n",
       "      <td>259.100100</td>\n",
       "      <td>-66.977648</td>\n",
       "      <td>1.042472</td>\n",
       "      <td>1267.040664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.082619</td>\n",
       "      <td>238244</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599350 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x          y        amp          area          u    age  \\\n",
       "0        242.258195  40.498931   2.994491  10809.049919        NaN   10.0   \n",
       "1        242.600100 -69.344310   0.125429   1307.723710        NaN   10.0   \n",
       "2        242.700100 -64.131685   3.458723   6708.039396   5.631560   10.0   \n",
       "3        245.400100 -61.955224  13.669557  10985.213312  26.323848   10.0   \n",
       "4        245.600100 -67.146695   0.551876   1666.310001        NaN   10.0   \n",
       "...             ...        ...        ...           ...        ...    ...   \n",
       "1599345  258.500100 -63.513617   6.218261   9476.326775  11.992946  125.0   \n",
       "1599346  258.600100 -55.425356   2.878914   6293.522627   8.810720   35.0   \n",
       "1599347  258.600100 -49.654134   0.655865   8606.090785        NaN   55.0   \n",
       "1599348  258.800100 -21.714382   0.378134   8417.142072        NaN   20.0   \n",
       "1599349  259.100100 -66.977648   1.042472   1267.040664        NaN   15.0   \n",
       "\n",
       "         radius_km      id  cyc  year  mon  day  \n",
       "0        58.656862       1    1     1    1    5  \n",
       "1        20.402485       2    1     1    1    5  \n",
       "2        46.208606       3    1     1    1    5  \n",
       "3        59.132918       4    1     1    1    5  \n",
       "4        23.030479       5    1     1    1    5  \n",
       "...            ...     ...  ...   ...  ...  ...  \n",
       "1599345  54.921840  230803   -1     5   12   31  \n",
       "1599346  44.758133  236814   -1     5   12   31  \n",
       "1599347  52.339314  235516   -1     5   12   31  \n",
       "1599348  51.761564  237872   -1     5   12   31  \n",
       "1599349  20.082619  238244   -1     5   12   31  \n",
       "\n",
       "[1599350 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = '/glade/p/cgd/oce/people/mclong/hi-res-eco/data/analysis/tracks_20161128'\n",
    "file_in = f'{pth}/0_pt_1_CESM_tracks.mat'\n",
    "tracks = pd.DataFrame(eddy_tracks.track_mat2py(file_in))\n",
    "tracks = tracks.rename(columns={\"Ls\": \"radius_km\"})\n",
    "tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make a dictionary of the hi-res days for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dict = {\n",
    "        \"jan\" : (5,10,15,20,25,30),\n",
    "        \"feb\" : (4,9,14,19,24),\n",
    "        \"mar\" : (1,6,11,16,21,26,31),\n",
    "        \"apr\" : (5,10,15,20,25,30),\n",
    "        \"may\" : (5,10,15,20,25,30),\n",
    "        \"jun\" : (4,9,14,19,24,29),\n",
    "        \"jul\" : (4,9,14,19,24,29),\n",
    "        \"aug\" : (3,8,13,18,23,28),\n",
    "        \"sep\" : (2,7,12,17,22,27),\n",
    "        \"oct\" : (2,7,12,17,22,27),\n",
    "        \"nov\" : (1,6,11,16,21,26),\n",
    "        \"dec\" : (1,6,11,16,21,26,31)\n",
    "        }\n",
    "\n",
    "month_dict = {\n",
    "        \"jan\" : 1,\n",
    "        \"feb\" : 2,\n",
    "        \"mar\" : 3,\n",
    "        \"apr\" : 4,\n",
    "        \"may\" : 5,\n",
    "        \"jun\" : 6,\n",
    "        \"jul\" : 7,\n",
    "        \"aug\" : 8,\n",
    "        \"sep\" : 9,\n",
    "        \"oct\" : 10,\n",
    "        \"nov\" : 11,\n",
    "        \"dec\" : 12\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan\n",
      "feb\n",
      "mar\n",
      "apr\n",
      "may\n",
      "jun\n",
      "jul\n",
      "aug\n",
      "sep\n",
      "oct\n",
      "nov\n",
      "dec\n"
     ]
    }
   ],
   "source": [
    "for month in month_dict:\n",
    "    print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_dict['dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set variables, select tracks, make eddy composites, saving them in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting month jan\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month feb\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month mar\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 6\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month apr\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month may\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month jun\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month jul\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month aug\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month sep\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "starting month oct\n",
      "doing day 0\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 1\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 2\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 3\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 4\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n",
      "doing day 5\n",
      "doing cyclonic TEMP\n",
      "got a 3-d var\n",
      "doing anticyclonic TEMP\n",
      "got a 3-d var\n"
     ]
    }
   ],
   "source": [
    "#first set variables and eddy characteristics\n",
    "variables = ['TEMP'] #['diatChl','PO4','TEMP','diat_N_lim','SSH','NO3','spC','Fe'] ############### set here!!\n",
    "    \n",
    "lat_max=-35\n",
    "lat_min=-45\n",
    "lon_max=360\n",
    "lon_min=0\n",
    "\n",
    "n_reps = 20      # number of repetitions for 9 pt smoother of databox\n",
    "threshold_r=4    #radius normalized distance threshold for including in composite\n",
    "\n",
    "age_min=30     #eddy age in days\n",
    "amp_min=1      #eddy amplitude in cm\n",
    "year=5        #year of high res run       \n",
    "\n",
    "radius_min=55\n",
    "radius_max=65\n",
    "\n",
    "#make empty dictionary to save the composite datasets for each month\n",
    "Cyclonic_monthly = dict()\n",
    "Anticyclonic_monthly = dict()\n",
    "\n",
    "for month_name in month_dict:\n",
    "    print('------starting month', month_name,'-----------')\n",
    "    \n",
    "    month=month_dict[month_name]\n",
    "\n",
    "    valid_eddies_cyc_sum=0\n",
    "    valid_eddies_anticyc_sum=0\n",
    "    counter=0\n",
    "    for day in day_dict[month_name]:\n",
    "        print('doing day', counter)\n",
    "        #sort by age, amplitude, size, lon/lat range, and eddy type\n",
    "        selected_eddies = tracks[(tracks.age >= age_min) & \n",
    "                                 (tracks.amp >= amp_min) & \n",
    "                                 (tracks.year == year) & \n",
    "                                 (tracks.mon == month) &\n",
    "                                 (tracks.day == day) & \n",
    "                                 (tracks.y < lat_max) &\n",
    "                                 (tracks.y > lat_min) &\n",
    "                                 (tracks.x < lon_max) &\n",
    "                                 (tracks.x > lon_min) &\n",
    "                                 (tracks.radius_km >= radius_min) &\n",
    "                                 (tracks.radius_km < radius_max)]\n",
    "\n",
    "        eddy_type=-1    #anticyclonic = 1, cyclonic=-1\n",
    "        selected_eddies_cyc = selected_eddies[(selected_eddies.cyc == eddy_type)]\n",
    "\n",
    "        eddy_type=1    #anticyclonic = 1, cyclonic=-1\n",
    "        selected_eddies_anticyc = selected_eddies[(selected_eddies.cyc == eddy_type)]\n",
    "\n",
    "        ##################################################################### Step 2: get the corresponding gridded data\n",
    "        case = 'g.e11.G.T62_t12.eco.006'\n",
    "        y4 = \"{:04d}\".format(year)\n",
    "        m2 = \"{:02d}\".format(month)\n",
    "        d2 = \"{:02d}\".format(day)\n",
    "\n",
    "        file = f'/glade/scratch/mclong/hi-res-eco/{case}/ocn/hist/{case}.pop.h.{y4}-{m2}-{d2}.nc'\n",
    "        ds = xr.open_dataset(file, decode_times=False, decode_coords=False)\n",
    "        coords = {'x':'TLONG','y':'TLAT'}\n",
    "        keep_vars = variables + list(coords.values())+['dz','KMT']\n",
    "        ds = ds.drop([v for v in ds.variables if v not in keep_vars]).squeeze()\n",
    "\n",
    "        ###################################################################### Step 3: make composites\n",
    "        ###### cyclonic\n",
    "        composite_ds_cyc = xr.Dataset()\n",
    "\n",
    "        for varname in variables:\n",
    "\n",
    "            print('doing cyclonic',varname)\n",
    "            var = ds[varname]\n",
    "            var.attrs=([]) #getting rid of attributes because it messes up the metpy smoother\n",
    "\n",
    "            if len(var.dims)>2: \n",
    "                composite, valid_eddies_cyc, databox = composite_a_3D_eddy(selected_eddies_cyc, ds, var, n_reps, threshold_r)\n",
    "            else:\n",
    "                composite, valid_eddies_cyc, databox = composite_a_2D_eddy(selected_eddies_cyc, ds, var, n_reps, threshold_r)\n",
    "\n",
    "            composite_ds_cyc[varname] = composite\n",
    "\n",
    "        ###### anticyclonic\n",
    "        composite_ds_anticyc = xr.Dataset()\n",
    "\n",
    "        for varname in variables:\n",
    "\n",
    "            print('doing anticyclonic',varname)\n",
    "            var = ds[varname]\n",
    "            var.attrs=([]) #getting rid of attributes because it messes up the metpy smoother\n",
    "\n",
    "            if len(var.dims)>2: \n",
    "                composite, valid_eddies_anticyc, databox = composite_a_3D_eddy(selected_eddies_anticyc, ds, var, n_reps, threshold_r)\n",
    "            else:\n",
    "                composite, valid_eddies_anticyc, databox = composite_a_2D_eddy(selected_eddies_anticyc, ds, var, n_reps, threshold_r)\n",
    "\n",
    "            composite_ds_anticyc[varname] = composite\n",
    "\n",
    "        # do running sum of anomalies, weighting by the number of valid eddies in each available day of the month\n",
    "        # 1st make a running total of the weights\n",
    "        valid_eddies_cyc_sum = valid_eddies_cyc_sum + valid_eddies_cyc\n",
    "        valid_eddies_anticyc_sum = valid_eddies_anticyc_sum + valid_eddies_anticyc\n",
    "\n",
    "        # Take each composite ds times the weights (number of valid eddies for this day)\n",
    "        if counter == 0:\n",
    "            all_cyc_comps = composite_ds_cyc * valid_eddies_cyc\n",
    "            all_anticyc_comps = composite_ds_anticyc * valid_eddies_anticyc\n",
    "        else:\n",
    "            all_cyc_comps = all_cyc_comps + composite_ds_cyc * valid_eddies_cyc\n",
    "            all_anticyc_comps = all_anticyc_comps + composite_ds_anticyc * valid_eddies_anticyc\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "\n",
    "    # Now divide by the sum of the weights \n",
    "    all_cyc_comps = all_cyc_comps / valid_eddies_cyc_sum\n",
    "    all_anticyc_comps = all_anticyc_comps / valid_eddies_anticyc_sum\n",
    "    \n",
    "    #save the composite datasets for this month in a dictionary\n",
    "    Cyclonic_monthly[month_name] = all_cyc_comps\n",
    "    Anticyclonic_monthly[month_name] = all_anticyc_comps\n",
    "    \n",
    "print('DONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save these composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month_name in month_dict:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyclonic_monthly['jan'].SSH.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyclonic_monthly['jan'].NO3.isel(lon=20).plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyclonic_monthly['jan'].TEMP.isel(lon=20).plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyclonic_monthly['jan'].NO3.isel(z_t=0).plot(yincrease=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyclonic_monthly['jan'].SSH.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot January composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp=len(variables)\n",
    "fig_width = num_comp * 2\n",
    "fig_height = (num_comp * 3) - 3\n",
    "rows = math.ceil(num_comp/2)\n",
    "cols = 2\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width,fig_height))\n",
    "count = 1\n",
    "for varname in variables:\n",
    "    ax = fig.add_subplot(rows,cols,count)\n",
    "    if count==1:\n",
    "        ax.set_title('CYCLONIC eddy composites')\n",
    "    var= Cyclonic_monthly['jan'][varname]\n",
    "    if len(var.dims)>2: \n",
    "        if var.dims[0]=='z_t':\n",
    "            var=var.isel(z_t=0)\n",
    "        else:\n",
    "            var=var.isel(z_t_150m=0)\n",
    "    \n",
    "    \n",
    "    pc=ax.pcolormesh(all_cyc_comps.lon, all_cyc_comps.lat, var, cmap='bwr')\n",
    "    cbar = fig.colorbar(pc, label=varname,extend='both')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp=len(variables)\n",
    "fig_width = num_comp * 2\n",
    "fig_height = (num_comp * 3) - 3\n",
    "rows = math.ceil(num_comp/2)\n",
    "cols = 2\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width,fig_height))\n",
    "count = 1\n",
    "for varname in variables:\n",
    "    ax = fig.add_subplot(rows,cols,count)\n",
    "    if count==1:\n",
    "        ax.set_title('ANTICYCLONIC eddy composites')\n",
    "    var= Anitcyclonic_monthly['jan'][varname]\n",
    "    if len(var.dims)>2: \n",
    "        if var.dims[0]=='z_t':\n",
    "            var=var.isel(z_t=0)\n",
    "        else:\n",
    "            var=var.isel(z_t_150m=0)\n",
    "    \n",
    "    \n",
    "    pc=ax.pcolormesh(all_cyc_comps.lon, all_cyc_comps.lat, var, cmap='bwr')\n",
    "    cbar = fig.colorbar(pc, label=varname,extend='both')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4b: PLOT anticyclonic eddy composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp=len(variables)\n",
    "fig_width = num_comp * 2\n",
    "fig_height = (num_comp * 3) - 3\n",
    "rows = math.ceil(num_comp/2)\n",
    "cols = 2\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width,fig_height))\n",
    "count = 1\n",
    "for varname in variables:\n",
    "    ax = fig.add_subplot(rows,cols,count)\n",
    "    var= all_anticyc_comps[varname]\n",
    "    if len(var.dims)>2: \n",
    "        if var.dims[0]=='z_t':\n",
    "            var=var.isel(z_t=0)\n",
    "        else:\n",
    "            var=var.isel(z_t_150m=0)\n",
    "    \n",
    "    pc=ax.pcolormesh(all_anticyc_comps.lon, all_anticyc_comps.lat, var, cmap='bwr')\n",
    "    cbar = fig.colorbar(pc, label=varname,extend='both')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertical section composites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclonic on left, anticyclonic on right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of 3d vars\n",
    "\n",
    "variables=['diatChl','PO4','TEMP','diat_N_lim','NO3']\n",
    "\n",
    "fig_width=10\n",
    "fig_height=len(variables)*2\n",
    "rows=len(variables)\n",
    "\n",
    "fig = plt.figure(figsize=(fig_width,fig_height))\n",
    "count = 1\n",
    "for varname in variables:\n",
    "    \n",
    "    ##### cyclonic\n",
    "    ax = fig.add_subplot(rows,cols,count)\n",
    "    ax.invert_yaxis()\n",
    "    var= all_cyc_comps[varname].sel(lat=0)\n",
    "\n",
    "    pc=ax.pcolormesh(var, cmap='bwr')\n",
    "    \n",
    "    cbar = fig.colorbar(pc, label=varname,extend='both')\n",
    "    count = count + 1\n",
    "    \n",
    "    ##### anticyclonic\n",
    "    ax = fig.add_subplot(rows,cols,count)\n",
    "    ax.invert_yaxis()\n",
    "    var= all_anticyc_comps[varname].sel(lat=0)\n",
    "\n",
    "    pc=ax.pcolormesh(var, cmap='bwr')\n",
    "    \n",
    "    cbar = fig.colorbar(pc, label=varname,extend='both')\n",
    "    count = count + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-analysis3]",
   "language": "python",
   "name": "conda-env-miniconda-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
